{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5P-oR8p4TZ8",
        "outputId": "2f5615f1-ab36-445f-95a1-8ec15e61cc60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.14.0-py3-none-any.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.8.0 (from gradio)\n",
            "  Downloading gradio_client-0.8.0-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/305.1 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio)\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.26.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/60.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBsS_Oz-iGQ"
      },
      "source": [
        "#KNN\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "okd2nSMX6TGG"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import os\n",
        "warnings.filterwarnings('ignore')\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import concurrent.futures\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "from io import StringIO\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "algorithms = [\"Logistic Regression\", \"KNN\", \"SVC\", \"Random Forest\", \"Gradient Boosting\", \"All\"]\n",
        "\n",
        "df = pd.read_csv('/content/heart.csv')\n",
        "test_data = pd.read_csv('/content/test.csv');\n",
        "#Drop the partient_id\n",
        "df.drop(columns=['Patient_ID'], inplace=True)\n",
        "\n",
        "# Separating features from the target we want to predict\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# Performing one-hot encoding for the categorical features\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Splitting our data into train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
        "\n",
        "# Standard scaling\n",
        "scaler = StandardScaler()\n",
        "st_scaled_X_train = scaler.fit_transform(X_train)\n",
        "st_scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "# Normal scaling\n",
        "scaler = MinMaxScaler()\n",
        "normal_scaled_X_train = scaler.fit_transform(X_train)\n",
        "normal_scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "# Storing out three types of data\n",
        "X_train_datasets = [X_train, st_scaled_X_train, normal_scaled_X_train]\n",
        "X_test_datasets = [X_test, st_scaled_X_test, normal_scaled_X_test]\n",
        "\n",
        "def knn():\n",
        "    knn = KNeighborsClassifier(n_neighbors=24, weights='distance')\n",
        "    knn = knn.fit(st_scaled_X_train, y_train)\n",
        "\n",
        "    predictions_knn = knn.predict(st_scaled_X_test)\n",
        "\n",
        "    knn_scores = []\n",
        "\n",
        "    knn_scores.append( score(y_test, predictions_knn, average='weighted')[0] )\n",
        "    knn_scores.append( score(y_test, predictions_knn, average='weighted')[1] )\n",
        "    knn_scores.append( score(y_test, predictions_knn, average='weighted')[2] )\n",
        "    knn_scores.append( accuracy_score(y_test, predictions_knn) )\n",
        "\n",
        "    df_knn = pd.DataFrame(knn_scores, columns=['knn'],\n",
        "                index=['Precision', 'Recall', 'f1_score', 'Accuracy'])\n",
        "\n",
        "    df_knn['knn'] = np.round(df_knn['knn'], 3)\n",
        "\n",
        "    return df_knn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYpBLVF6-c_c"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "485RvNJIuqtG"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "def logistic_reg():\n",
        "    # Setting up our three logistic regression models.\n",
        "\n",
        "    lr = LogisticRegression(solver='liblinear')\n",
        "    lr_l1 = LogisticRegressionCV(Cs=10, cv=5, penalty='l1', solver='liblinear')\n",
        "    lr_l2 = LogisticRegressionCV(Cs=10, cv=5, penalty='l2', solver='liblinear')\n",
        "\n",
        "    models = [lr, lr_l1, lr_l2]\n",
        "    precision = []\n",
        "    recall = []\n",
        "    f1_score = []\n",
        "    accuracy = []\n",
        "\n",
        "    for X_train_data, X_test_data in zip(X_train_datasets, X_test_datasets):\n",
        "        for model in models:\n",
        "\n",
        "            model.fit(X_train_data, y_train)\n",
        "\n",
        "            predictions = model.predict(X_test_data)\n",
        "\n",
        "            precision.append( score(y_test, predictions, average='weighted')[0] )\n",
        "            recall.append( score(y_test, predictions, average='weighted')[1] )\n",
        "            f1_score.append( score(y_test, predictions, average='weighted')[2] )\n",
        "            accuracy.append( accuracy_score(y_test, predictions) )\n",
        "    scores = [precision, recall, f1_score, accuracy]\n",
        "\n",
        "    df_lr = round(pd.DataFrame(scores,\n",
        "                index=['Precision', 'Recall', 'f1_score', 'Accuracy'],\n",
        "                columns=['lr', 'lr_l1', 'lr_l2',\n",
        "                        'lr_st', 'lr_l1_st', 'lr_l2_st',\n",
        "                        'lr_normal', 'lr_l1_normal', 'lr_l2_normal']), 3)\n",
        "\n",
        "    # Our chosen logistic regression model\n",
        "    # And trained on data without scaling\n",
        "\n",
        "    lr = LogisticRegression(solver='liblinear').fit(X_train, y_train)\n",
        "    predictions_lr = lr.predict(X_test)\n",
        "\n",
        "    # Storing the scores\n",
        "\n",
        "    df_lr = df_lr['lr'].to_frame()\n",
        "    return df_lr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4JM4boT-bd7"
      },
      "source": [
        "#SVC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2xOUi1QY8c8H"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "def svc():\n",
        "    svc = SVC()\n",
        "    svc = svc.fit(st_scaled_X_train, y_train)\n",
        "\n",
        "    predictions_svc = svc.predict(st_scaled_X_test)\n",
        "\n",
        "    svc_scores = []\n",
        "\n",
        "    svc_scores.append( score(y_test, predictions_svc, average='weighted')[0] )\n",
        "    svc_scores.append( score(y_test, predictions_svc, average='weighted')[1] )\n",
        "    svc_scores.append( score(y_test, predictions_svc, average='weighted')[2] )\n",
        "    svc_scores.append( accuracy_score(y_test, predictions_svc) )\n",
        "\n",
        "    df_svc = pd.DataFrame(svc_scores, columns=['svc'],\n",
        "                index=['Precision', 'Recall', 'f1_score', 'Accuracy'])\n",
        "\n",
        "    df_svc['svc'] = np.round(df_svc['svc'], 3)\n",
        "\n",
        "    return df_svc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7iQBa1V-RjE"
      },
      "source": [
        "#Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OuFR6j939N4L"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RF = RandomForestClassifier(oob_score=True,\n",
        "                            random_state=42,\n",
        "                            warm_start=True,\n",
        "                            n_jobs=-1)\n",
        "\n",
        "def random_forest():\n",
        "    rf = RF.set_params(n_estimators=100, warm_start=False)\n",
        "    rf = rf.fit(X_train, y_train)\n",
        "\n",
        "    predictions_rf = rf.predict(X_test)\n",
        "\n",
        "    rf_scores = []\n",
        "\n",
        "    rf_scores.append( score(y_test, predictions_rf, average='weighted')[0] )\n",
        "    rf_scores.append( score(y_test, predictions_rf, average='weighted')[1] )\n",
        "    rf_scores.append( score(y_test, predictions_rf, average='weighted')[2] )\n",
        "    rf_scores.append( accuracy_score(y_test, predictions_rf) )\n",
        "\n",
        "    df_rf = pd.DataFrame(rf_scores, columns=['rf'],\n",
        "                index=['Precision', 'Recall', 'f1_score', 'Accuracy'])\n",
        "\n",
        "    df_rf['rf'] = np.round(df_rf['rf'], 3)\n",
        "\n",
        "    return df_rf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmW8DjYM-V9m"
      },
      "source": [
        "#Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0h-cICA99gVQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "def gradient_boosting():\n",
        "    gb = GradientBoostingClassifier(n_estimators=30, random_state=42)\n",
        "    gb = gb.fit(X_train, y_train)\n",
        "\n",
        "    predictions_gb = gb.predict(X_test)\n",
        "\n",
        "    gb_scores = []\n",
        "\n",
        "    gb_scores.append( score(y_test, predictions_gb, average='weighted')[0] )\n",
        "    gb_scores.append( score(y_test, predictions_gb, average='weighted')[1] )\n",
        "    gb_scores.append( score(y_test, predictions_gb, average='weighted')[2] )\n",
        "    gb_scores.append( accuracy_score(y_test, predictions_gb) )\n",
        "\n",
        "    df_gb = pd.DataFrame(gb_scores, columns=['gb'],\n",
        "                index=['Precision', 'Recall', 'f1_score', 'Accuracy'])\n",
        "\n",
        "    df_gb['gb'] = np.round(df_gb['gb'], 3)\n",
        "\n",
        "    return df_gb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZbsUwVjZMsTm"
      },
      "outputs": [],
      "source": [
        "def all():\n",
        "    return pd.concat([logistic_reg(), knn(), svc(), random_forest(), gradient_boosting()], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "DhcfjTb-YWvI"
      },
      "outputs": [],
      "source": [
        "max_acc_lr = logistic_reg()['lr'].values[3]\n",
        "max_acc_knn = knn()['knn'].values[3]\n",
        "max_acc_svc = svc()['svc'].values[3]\n",
        "max_acc_rf = random_forest()['rf'].values[3]\n",
        "max_acc_gb = gradient_boosting()['gb'].values[3]\n",
        "\n",
        "simple = pd.DataFrame(\n",
        "    {\n",
        "        \"Algorithms\": [\"KNN\", \"Logistic Regression\", \"SVC\", \"Random Forest\", \"Gradient Boosting\"],\n",
        "        \"Accuracy\": [max_acc_knn, max_acc_lr, max_acc_svc, max_acc_rf, max_acc_gb],\n",
        "    }\n",
        ")\n",
        "\n",
        "accuracy_data = simple.set_index('Algorithms')['Accuracy'].to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ohCeZ6Qv_Zi7"
      },
      "outputs": [],
      "source": [
        "def test_algorithms(algorithm, features):\n",
        "    predictions = None\n",
        "    y = df['HeartDisease']\n",
        "\n",
        "    X = pd.get_dummies(df[features])\n",
        "    X_test = pd.get_dummies(test_data[features])\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    st_scaled_X_train = scaler.fit_transform(X)\n",
        "    st_scaled_X_test = scaler.transform(X_test)\n",
        "\n",
        "    if algorithm == \"KNN\":\n",
        "        model = KNeighborsClassifier(n_neighbors=24, weights='distance')\n",
        "        model.fit(st_scaled_X_train, y)\n",
        "        predictions = model.predict(st_scaled_X_test)\n",
        "\n",
        "    elif algorithm == \"Logistic Regression\":\n",
        "        model = LogisticRegression(solver='liblinear')\n",
        "        model.fit(X, y)\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "    elif algorithm == \"SVC\":\n",
        "        model = SVC()\n",
        "        model.fit(st_scaled_X_train, y)\n",
        "        predictions = model.predict(st_scaled_X_test)\n",
        "\n",
        "\n",
        "    elif algorithm == \"Random Forest\":\n",
        "        model = RandomForestClassifier(oob_score=True,\n",
        "                            random_state=42,\n",
        "                            warm_start=True,\n",
        "                            n_jobs=-1).set_params(n_estimators=150, warm_start=False)\n",
        "        model.fit(X, y)\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "    elif algorithm == \"Gradient Boosting\":\n",
        "        model = GradientBoostingClassifier(n_estimators=30, random_state=42)\n",
        "        model.fit(X, y)\n",
        "        predictions = model.predict(X_test)\n",
        "\n",
        "    elif algorithm == \"All\":\n",
        "        predictions = None\n",
        "\n",
        "    for dirname, _, filenames in os.walk('/content'):\n",
        "            for filename in filenames:\n",
        "                if filename == 'submission.csv':\n",
        "                    os.remove(os.path.join(dirname, filename))\n",
        "\n",
        "    output = pd.DataFrame({'Patient_ID' : test_data.Patient_ID, 'HeartDisease' : predictions})\n",
        "\n",
        "    output.to_csv('submission.csv', index=False)\n",
        "\n",
        "    first_five_output = pd.read_csv('submission.csv', nrows=10)\n",
        "\n",
        "    return first_five_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Z-7oKjUr0-L5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "outputId": "a4637dea-793f-44a9-fade-72eadcaefde2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a6350eb254ad9bb689.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a6350eb254ad9bb689.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Function to execute functions concurrently and gather results (Parallel Code)\n",
        "def show_df(algorithm):\n",
        "    functions = {\n",
        "        \"Logistic Regression\": logistic_reg,\n",
        "        \"KNN\": knn,\n",
        "        \"SVC\": svc,\n",
        "        \"Random Forest\": random_forest,\n",
        "        \"Gradient Boosting\": gradient_boosting,\n",
        "        \"All\": all\n",
        "    }\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        result = executor.submit(functions[algorithm])\n",
        "        return result.result()\n",
        "\n",
        "# Sorting the accuracy values\n",
        "sorted_accuracy = {k: v for k, v in sorted(accuracy_data.items(), key=lambda item: item[1], reverse=True)}\n",
        "\n",
        "# Function to display accuracy line plot\n",
        "def display_accuracy():\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(list(sorted_accuracy.keys()), list(sorted_accuracy.values()), marker='o', linestyle='-', color='b')\n",
        "    plt.title('Accuracy of Different Algorithms')\n",
        "    plt.xlabel('Algorithms')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return plt\n",
        "\n",
        "# Function to display accuracy bar plot\n",
        "def bar_plot_fn():\n",
        "        return gr.BarPlot(\n",
        "            simple,\n",
        "            x=\"Algorithms\",\n",
        "            y=\"Accuracy\",\n",
        "            title=\"Algorithm Accuracy Comparison\",\n",
        "            tooltip=[\"Algorithms\", \"Accuracy\"],\n",
        "            y_lim=[0.0, 1.0],\n",
        "        )\n",
        "\n",
        "# Creating Gradio interface1\n",
        "with gr.Blocks() as interface1:\n",
        "    with gr.Tab(\"Line Plot\"):\n",
        "        gr.Interface(\n",
        "            fn=display_accuracy,\n",
        "            title='Algorithm Accuracy Comparison',\n",
        "            description='Line plot showing accuracy of different algorithms',\n",
        "            inputs=None,\n",
        "            outputs=gr.Plot(label=\"Accuracy Plot\")\n",
        "        )\n",
        "    with gr.Tab(\"Bar Plot\"):\n",
        "        plot = gr.BarPlot()\n",
        "    interface1.load(fn=bar_plot_fn, inputs=None, outputs=plot)\n",
        "\n",
        "# Creating Gradio interface2\n",
        "interface2 = gr.Interface(\n",
        "    fn = show_df,\n",
        "    inputs = gr.Dropdown(choices=algorithms, label=\"Select an Algorithm\"),\n",
        "    outputs = gr.DataFrame(headers=['lr', 'knn', 'svc', 'rf', 'gb'], label=\"Output\", row_count=4, col_count=5)\n",
        ")\n",
        "\n",
        "# Creating Gradio interface3\n",
        "with gr.Blocks() as interface3:\n",
        "    with gr.Tab(\"Test\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                choice = gr.Dropdown(choices=algorithms, label=\"Select an Algorithm\")\n",
        "                submit_btn = gr.Button(\"Submit\")\n",
        "            with gr.Column():\n",
        "                feature_choice = gr.CheckboxGroup([\"Sex\", \"ChestPainType\", \"RestingECG\", \"ExerciseAngina\", \"ST_Slope\", \"Age\",\n",
        "                                        \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"Oldpeak\"],\n",
        "                                        label=\"Feature Selection\")\n",
        "\n",
        "        output = gr.DataFrame(label=\"Output\", headers=['Patient_ID', 'HeartDisease'], col_count=2, row_count=10)\n",
        "        # output = gr.Text(label=\"Output\", type=\"text\")\n",
        "        submit_btn.click(fn=test_algorithms, inputs=[choice, feature_choice], outputs=output, api_name='Heart')\n",
        "\n",
        "\n",
        "# Creating Gradio TabbedInterface\n",
        "interface = gr.TabbedInterface([interface2, interface1, interface3], [\"Compare Algorithms\", \"Plot the Accuracy\", \"Test the Output\"])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "CGPRQLDivgvq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}